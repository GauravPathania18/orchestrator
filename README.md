# Personal LLM RAG System

A modular, production-ready **Retrieval-Augmented Generation (RAG)** system with three microservices.

## ğŸ¯ Overview

This project implements a personal knowledge management system that:
- **Embeds** text documents into high-dimensional vectors
- **Stores** vectors in ChromaDB for semantic search
- **Retrieves** relevant documents based on queries
- **Generates** responses using LLMs (via Ollama)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Backend Orchestrator (8002)         â”‚
â”‚  â€¢ /chat - Query with context               â”‚
â”‚  â€¢ /memory - Store documents                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“        â†“        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Embed  â”‚ â”‚Vector  â”‚ â”‚ Ollama   â”‚
â”‚(8000) â”‚ â”‚Storage â”‚ â”‚  LLM     â”‚
â”‚       â”‚ â”‚(8003)  â”‚ â”‚(11434)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Three Microservices**

1. **Embedding Service** (Port 8000)
   - Converts text â†’ 768-dim vectors
   - Uses `sentence-transformers`
   - Endpoint: `/embed`

2. **Vector Storage** (Port 8003)
   - Persistent vector database
   - Built on ChromaDB
   - Endpoints: `/add_text`, `/query_text`, `/vectors`

3. **Backend Orchestrator** (Port 8002)
   - Coordinates all services
   - Implements RAG pipeline
   - Endpoints: `/chat`, `/memory`

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Virtual environment: `.venv/`
- Dependencies installed: `pip install -r requirements.txt`

### Start Services (3 Terminals)

**Terminal 1 - Embedding Service:**
```bash
cd personal_LLM_embedder
python embedder_api.py
# Runs on http://localhost:8000
```

**Terminal 2 - Vector Storage:**
```bash
cd VECTOR_STORAGE_SERVICE
python run.py
# Runs on http://localhost:8003
```

**Terminal 3 - Backend:**
```bash
cd Backend
python -m uvicorn app.main:app --reload --port 8002
# Runs on http://localhost:8002
```

### Test the System

**Store a memory:**
```bash
curl -X POST http://localhost:8002/memory \
  -H "Content-Type: application/json" \
  -d '{"text":"Paris is famous for the Eiffel Tower","session_id":"user1"}'
```

**Ask a question:**
```bash
curl -X POST http://localhost:8002/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"What is Paris famous for?","session_id":"user1"}'
```

**View stored vectors:**
```bash
curl http://localhost:8003/vectors
```

---

## ğŸ“ Project Structure

```
PROJECT/
â”œâ”€â”€ .env                      # Configuration (ports, URLs, settings)
â”œâ”€â”€ .venv/                    # Virtual environment (11 packages)
â”œâ”€â”€ .vscode/                  # VS Code settings & debug config
â”œâ”€â”€ Backend/                  # Main orchestrator service
â”‚   â”œâ”€â”€ app/main.py
â”‚   â”œâ”€â”€ app/api/
â”‚   â”œâ”€â”€ app/core/
â”‚   â”œâ”€â”€ app/schemas/
â”‚   â””â”€â”€ app/services/
â”œâ”€â”€ personal_LLM_embedder/    # Embedding service
â”‚   â””â”€â”€ embedder_api.py
â”œâ”€â”€ VECTOR_STORAGE_SERVICE/   # Vector database service
â”‚   â””â”€â”€ app/
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ pyproject.toml
```

---

## ğŸ“¦ Dependencies

**11 total packages:**
```
fastapi, uvicorn, pydantic, chromadb, httpx, requests,
python-dotenv, beautifulsoup4, sentence-transformers, numpy, huggingface-hub
```

Install: `pip install -r requirements.txt`

---

## ğŸ”§ Configuration

Edit `.env`:
```bash
EMBEDDER_URL=http://127.0.0.1:8000/embed
VECTOR_STORAGE_URL=http://localhost:8003
OLLAMA_URL=http://localhost:11434
PERSIST_DIR=./chroma_store
```

---

## ğŸ“š API Documentation

- **Embedding:** http://localhost:8000/docs
- **Vector Storage:** http://localhost:8003/docs
- **Backend:** http://localhost:8002/docs

---

## ğŸ› Troubleshooting

| Issue | Solution |
|-------|----------|
| Services won't start | Activate venv: `.venv\Scripts\Activate.ps1` |
| Import errors | Reinstall: `pip install -r requirements.txt` |
| Port conflicts | Check: `netstat -ano \| findstr :8000` |
| ChromaDB errors | Clear cache: `rmdir /s chroma_store` |

---

## ğŸ“„ License

See [LICENSE](LICENSE)

---

**Status:** âœ… Production Ready | **Python:** 3.10+ | **Last Updated:** February 2026
